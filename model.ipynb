{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import ssl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchvision.models._api import WeightsEnum\n",
    "# Turn of SSL verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom transform for PyTorch\n",
    "\"\"\"\n",
    "class GreyscaleContrast(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = np.array(img)                          # Convert image from PIL to numpy array\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to greyscale\n",
    "        img = cv2.equalizeHist(img)                  # Apply histogram equalization\n",
    "        img = Image.fromarray(img)                   # Create PIL image from numpy array\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom dataset for PyTorch\n",
    "\"\"\"\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, threshold=True):\n",
    "        \"\"\"\n",
    "        Initialises the Dataset object\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir                    # Directory with training data\n",
    "        self.transform = transform                  # Data transforms\n",
    "        self.threshold = threshold                  # Threshold is true if the task is binary classification, false otherwise\n",
    "        self.image_paths = [                        # Construct a list with image filenames\n",
    "            os.path.join(data_dir, filename)\n",
    "            for filename in os.listdir(data_dir)\n",
    "            if filename.endswith(\".jpg\")\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data samples \n",
    "        \"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the image and label of specified sample\n",
    "        \"\"\"\n",
    "        image_path = self.image_paths[idx]         \n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_path = os.path.join(self.data_dir, f\"{image_name}.json\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        with open(label_path, \"r\") as f:\n",
    "            label_data = json.load(f)\n",
    "        colonies_number = label_data[\"colonies_number\"]\n",
    "        if self.threshold:\n",
    "            colonies_number = min(colonies_number, 1)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, colonies_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Specify the loaction of training data\n",
    "Select the task: binary classification or regression\n",
    "Define training data transformations, random image pre-processing\n",
    "Create dataset\n",
    "\"\"\"\n",
    "data_directory = \"train_data_resized\"\n",
    "binary_classification = True\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "dataset = CustomDataset(data_dir=data_directory, transform=transform, threshold=binary_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select a sample size to not use the whole dataset for training\n",
    "Calculate a size of training and validation dataset\n",
    "Set a batch size \n",
    "Create a dataloader for training and validation dataset\n",
    "\"\"\"\n",
    "sample_size = 500 if 500 < len(dataset) else len(dataset)\n",
    "train_size = int(0.9 * sample_size)\n",
    "val_size = sample_size - train_size\n",
    "train_dataset, val_dataset, _ = random_split(dataset, [train_size, val_size, (len(dataset) - train_size - val_size)])\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the whole dataset for training\n",
    "\"\"\"\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.98 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Specify number of epochs and learning rate\n",
    "Select a model,\n",
    "Specify the number of input and output features for the last layer, and the function to map real value to binary output\n",
    "Select the device for training, loss function and optimizer\n",
    "\"\"\"\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "WeightsEnum.get_state_dict = get_state_dict\n",
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "model = efficientnet_b0(weights=\"DEFAULT\")\n",
    "num_ftrs = 1280\n",
    "model.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "device = torch.device(\"cpu\")  # (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Metric that we will be evaluated on for competition\n",
    "\"\"\"\n",
    "def eval(y_true, y_pred):\n",
    "    score = accuracy_score(y_true, y_pred) * recall_score(y_true, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training loop\n",
    "\"\"\"\n",
    "best_val = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs >= threshold).int()\n",
    "\n",
    "        \n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    official_score = 0\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "       \n",
    "        threshold = 0.5\n",
    "        predicted = (outputs >= threshold).int()\n",
    "\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "        official_score += eval(labels.flatten().cpu(), predicted.flatten().cpu())\n",
    "\n",
    "    avg_val_loss = val_loss / val_total\n",
    "    avg_official_score = official_score / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Official score: {avg_official_score:.4f}\"\n",
    "    )\n",
    "    if avg_official_score > best_val:\n",
    "        best_val = avg_official_score\n",
    "        torch.save(model.state_dict(), \"agar3000.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
